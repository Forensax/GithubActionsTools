name: Deploy Ollama Model

on:
  workflow_dispatch:
    inputs:
      model:
        description: '模型名称'
        required: true
        default: 'deepseek-r1:14b'

jobs:
  Deploy:
    runs-on: ubuntu-latest
    steps:
      - name: 迁出代码
        uses: actions/checkout@v3

      - name: 检查服务器配置
        id: check_server
        run: |
          CONFIG=$(cat <<EOF
已知CPU型号(性能降序): 7763，8370C，8272CL，8171M，E5-2673

--------------------------CPU信息--------------------------
CPU物理数量: $(cat /proc/cpuinfo | grep 'physical id' | sort | uniq | wc -l)
CPU核心数量: $(nproc)
CPU型号信息: $(cat /proc/cpuinfo | grep -m1 name | awk -F: '{print \$2}')

--------------------------内存信息--------------------------
已安装内存详细信息:
$(sudo lshw -short -C memory | grep GiB)

--------------------------硬盘信息--------------------------
硬盘数量: $(ls /dev/sd* | grep -v [1-9] | wc -l)
$(df -hT)

--------------------------网络信息--------------------------
$(curl -s -4 ipinfo.io | jq -r '
"IP地址           \(.ip)\n" +
"所在城市         \(.city)\n" +
"所在区域         \(.region)\n" +
"国家             \(.country)\n" +
"地理位置         \(.loc)\n" +
"组织             \(.org)\n" +
"邮政编码         \(.postal)\n" +
"所在时区         \(.timezone)\n')
EOF
)
          # 将所有配置信息保存为输出变量（多行文本需使用特殊语法）
          echo "server_config<<EOF" >> $GITHUB_OUTPUT
          echo "$CONFIG" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: 加入Tailscale私有网络
        uses: tailscale/github-action@v3
        with:
          oauth-client-id: ${{ secrets.TS_OAUTH_CLIENT_ID }}
          oauth-secret: ${{ secrets.TS_OAUTH_SECRET }}
          tags: tag:githubactions
          version: latest

      - name: 查看IP地址
        id: get_local_ip
        run: |
          ip a
          # 过滤提取以 100. 开头的本地 IP 地址
          LOCAL_IP=$(ip -o -4 addr list | awk '/100\./ {print $4}' | cut -d/ -f1)
          echo "提取到本地 IP: ${LOCAL_IP}"
          echo "local_ip=${LOCAL_IP}" >> $GITHUB_OUTPUT

      - name: 安装Ollama
        run: |
          curl -fsSL https://ollama.com/install.sh | sh

      - name: 部署选定模型
        run: |
          echo "开始部署模型：${{ github.event.inputs.model }}"
          ollama run ${{ github.event.inputs.model }}

      - name: 部署Open WebUI
        run: |
          echo "开始部署Open WebUI:"
          docker run -d --network=host -v open-webui:/app/backend/data -e OLLAMA_BASE_URL=http://127.0.0.1:11434 --name open-webui --restart always ghcr.io/open-webui/open-webui:main
          echo "地址：IP:8080"

      - name: 发送通知
        uses: appleboy/telegram-action@master
        with:
          to: ${{ secrets.TELEGRAM_TO }}
          token: ${{ secrets.TELEGRAM_TOKEN }}
          message: |
            大模型部署完成：
            模型: ${{ github.event.inputs.model }}
            
            服务器配置信息:
            ${{ steps.check_server.outputs.server_config }}
            
            本地IP: ${{ steps.get_local_ip.outputs.local_ip }}
            WEB地址: http://${{ steps.get_local_ip.outputs.local_ip }}:8080

      - name: 启动SSH终端
        uses: mxschmitt/action-tmate@v3
